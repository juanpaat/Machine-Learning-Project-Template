{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOeyaL9ovjKoGIYAMeACpw6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanpaat/Machine-Learning-Project-Template/blob/main/Template_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKsCe0Hyy4GT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross-Validation"
      ],
      "metadata": {
        "id": "VhcffKwL24__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train-Test-Split  \n",
        "\n",
        "Train-test-split is the simplest form of cross-validation. We simply randomly slice our dataset into a training set and testing set. Typically, the most important parameters are:\n",
        "\n",
        "*  `X`: The feature set you're looking to split.\n",
        "\n",
        "*  `y`: The target variable you're looking to split.\n",
        "\n",
        "*  `test_size`: The size of your testing set. Typically, this is denoted as a fraction such as `0.33`.\n",
        "\n",
        "*  `random_state`: This is the seed of the random shuffle. I recommend setting a seed so everytime you rerun your notebook, your results stay consistent.\n",
        "\n",
        "*  `stratify`: This is an optional argument. But stratifying will reduce the variance in the random shuffle to ensure that your training and testing sets are more similar than not.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u8tzxP0m28Bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "features = [\n",
        "    'amount',\n",
        "    'oldbalanceOrg',\n",
        "    'newbalanceOrig',\n",
        "    'oldbalanceDest',\n",
        "    'newbalanceDest'\n",
        "]\n",
        "\n",
        "X = df[features]\n",
        "y = df['isFraud']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=42)"
      ],
      "metadata": {
        "id": "y-CDJLCo4Zsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Fold Cross Validation  \n",
        "\n",
        "Import parameters we should keep in mind:\n",
        "\n",
        "*  `n_splits`: This is the number of splits we want to make within our dataset.\n",
        "\n",
        "*  `shuffle`: This tells us whether we should shuffle our data before splitting into folds.\n",
        "\n",
        "*  `random_state`: This is the random seed we're setting, similar to train-test-split."
      ],
      "metadata": {
        "id": "cgmi59Lm2798"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=2, shuffle = True, random_state = 42)\n",
        "kf.get_n_splits(X)\n",
        "\n",
        "folds = {}\n",
        "\n",
        "for train, test in kf.split(X):\n",
        "    # Fold\n",
        "    fold_number = 1\n",
        "    # Store fold number\n",
        "    folds[fold_number] = (df.iloc[train], df.iloc[test])\n",
        "    print('train: %s, test: %s' % (df.iloc[train], df.iloc[test]))\n",
        "    fold_number += 1"
      ],
      "metadata": {
        "id": "jVMTuf0j5TBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Typically, after completing K-Fold Cross-Validation we'll want to calculate a cross-validation score. Typically, we'll get the scores for each fold, then take an average"
      ],
      "metadata": {
        "id": "rqY057dZ5nOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores))"
      ],
      "metadata": {
        "id": "psw8RDXH5kWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leave-One-Out Cross Validation\n"
      ],
      "metadata": {
        "id": "2MTMQzY_4Cw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "loo = LeaveOneOut()\n",
        "loo.get_n_splits(X)\n",
        "\n",
        "\n",
        "all_preds = []\n",
        "\n",
        "for train_index, test_index in loo.split(X[:100]):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    model = RandomForestClassifier()\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_preds = model.predict(X_test)\n",
        "\n",
        "    correct = y_preds[0] == y_test.values[0]\n",
        "\n",
        "    all_preds.append(correct)"
      ],
      "metadata": {
        "id": "URNEn-EM5ubr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(all_preds)/len(all_preds)"
      ],
      "metadata": {
        "id": "lgewYahx5xb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train-Test-Split Date Split  \n",
        "\n",
        "In many instances, you don't want to randomly slice your data into training and testing sets, but instead, you want to split it by time. In this case, you'll want to split by date:"
      ],
      "metadata": {
        "id": "bbX-0jHs277h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATE = '2021-12-31'\n",
        "\n",
        "train_df = df[df['date'] < DATE].copy()\n",
        "test_df = df[df['date'] >= DATE].copy()\n",
        "\n",
        "X_train = train_df[features]\n",
        "X_test = test_df[features]\n",
        "\n",
        "y_train = train_df['isFraud']\n",
        "y_test = test_df['isFraud']\n",
        "\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_preds = model.predict(X_test)\n",
        "\n",
        "print(average_precision_score(y_preds, y_test))"
      ],
      "metadata": {
        "id": "EK8MLZo853FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sliding Window/Time Series KFold"
      ],
      "metadata": {
        "id": "DjjUql06275Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "tscv = TimeSeriesSplit()\n",
        "\n",
        "all_scores = []\n",
        "\n",
        "for train_index, test_index in tscv.split(X):\n",
        "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    model = RandomForestClassifier()\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_preds = model.predict(X_test)\n",
        "\n",
        "    pr_auc = average_precision_score(y_preds, y_test)\n",
        "\n",
        "    all_scores.append(pr_auc)\n",
        "\n",
        "\n",
        "print(all_scores)"
      ],
      "metadata": {
        "id": "yIfE5tEZ6YSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Expanding Window"
      ],
      "metadata": {
        "id": "RDCTOEev273G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ExpandingWindowCV:\n",
        "    def fit(self, date_col, date_range = None, custom_range = None):\n",
        "        self.date_col = date_col\n",
        "        self.date_range = date_range\n",
        "        self.custom_range = custom_range\n",
        "\n",
        "        if date_range is not None and custom_range is not None:\n",
        "            raise ValueError(\"Date Range and Custom Range both cannot be None.\")\n",
        "\n",
        "    def split(self, df):\n",
        "        if self.date_range is None:\n",
        "            dates = list(set(df[self.date_col].astype(str).values))\n",
        "\n",
        "        if self.date_range is not None:\n",
        "            dates = pd.date_range(start=self.date_range[0], end=self.date_range[1])\n",
        "            dates = [str(d.date()) for d in dates]\n",
        "\n",
        "        if self.custom_range is not None:\n",
        "            dates = self.custom_range\n",
        "\n",
        "        for d in dates:\n",
        "            df_train = df[df[self.date_col].astype(str) <= d].copy()\n",
        "            df_test = df[df[self.date_col].astype(str) > d].copy()\n",
        "            yield df_train, df_test\n",
        "\n",
        "ew = ExpandingWindowCV()\n",
        "ew.fit(date_col = 'date', date_range = ['2022-01-02','2022-01-08'])\n",
        "ew.split(df)"
      ],
      "metadata": {
        "id": "9Sqgb86x6duz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_scores = []\n",
        "\n",
        "for train_df, test_df in ew.split(df):\n",
        "    X_train = train_df[features]\n",
        "    X_test = test_df[features]\n",
        "\n",
        "    y_train = train_df['isFraud']\n",
        "    y_test = test_df['isFraud']\n",
        "\n",
        "\n",
        "    model = RandomForestClassifier()\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_preds = model.predict(X_test)\n",
        "\n",
        "    pr_auc = average_precision_score(y_preds, y_test)\n",
        "\n",
        "    all_scores.append(pr_auc)\n",
        "\n",
        "all_scores"
      ],
      "metadata": {
        "id": "t75n1pNE6fbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Monte Carlo Cross Validation  \n",
        "\n",
        "Monte Carlos Cross Validation is where we randomly select a sub-sample (with replacement) from our dataset for the training set, use the rest for the testing set. Repeat this (with replacement) N number of times, to create a distribution of evaluation scores."
      ],
      "metadata": {
        "id": "tpaSg2aZ270T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "rs = ShuffleSplit(n_splits=5, test_size=.25, random_state=0)\n",
        "rs.get_n_splits(df)\n",
        "\n",
        "all_scores = []\n",
        "for train_index, test_index in rs.split(df):\n",
        "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    model = RandomForestClassifier()\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_preds = model.predict(X_test)\n",
        "\n",
        "    pr_auc = average_precision_score(y_preds, y_test)\n",
        "\n",
        "    all_scores.append(pr_auc)"
      ],
      "metadata": {
        "id": "lggB_fsz63kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_scores"
      ],
      "metadata": {
        "id": "vFP4bgGb4LNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models Classification\n",
        "\n"
      ],
      "metadata": {
        "id": "_fVSqDT89qBU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.datacamp.com/cheat-sheet/machine-learning-cheat-sheet"
      ],
      "metadata": {
        "id": "BVrizuw4FlBi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Model                 | Regression | Classification |\n",
        "| :--------------------: | :--------: | :------------: |\n",
        "| Linear Regression     |      X     |                |\n",
        "| Logistic Regression   |            |        X       |\n",
        "| Ridge Regression      |      X     |                |\n",
        "| Lasso Regression      |      X     |                |\n",
        "| K-Nearest Neighbours  |      X     |        X       |\n",
        "| Decision Trees        |      X     |        X       |\n",
        "| Naïve Bayes           |            |        X       |\n",
        "| SVM                   |      X     |        X       |\n",
        "| Random Forest         |      X     |        X       |\n",
        "| XGBoost               |      X     |        X       |"
      ],
      "metadata": {
        "id": "v0SH6M-m-sKR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree"
      ],
      "metadata": {
        "id": "A0FWR_K1DP-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
      ],
      "metadata": {
        "id": "GjY5bpaa5OpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split dataset in features and target variable\n",
        "feature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree']\n",
        "X = pima[feature_cols] # Features\n",
        "y = pima.NameOfTheTarget # Target variable"
      ],
      "metadata": {
        "id": "dQ_vfNoI5U5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test"
      ],
      "metadata": {
        "id": "_ucZ2OB-5g7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Decision Tree classifer object\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train,y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "t61yuczZ5kNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  **criterion : optional (default=”gini”) or Choose attribute selection measure.**\n",
        "This parameter allows us to use the different-different attribute selection measure. Supported criteria are “gini” for the Gini index and “entropy” for the information gain.\n",
        "\n",
        "*  **splitter : string, optional (default=”best”) or Split Strategy.** This parameter allows us to choose the split strategy. Supported strategies are “best” to choose the best split and “random” to choose the best random split.\n",
        "\n",
        "*  **max_depth : int or None, optional (default=None) or Maximum Depth of a Tree.** The maximum depth of the tree. If None, then nodes are expanded until all the leaves contain less than min_samples_split samples. The higher value of maximum depth causes overfitting, and a lower value causes underfitting (Source)."
      ],
      "metadata": {
        "id": "BgN2vfOO56Ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizing Decision Tree Performance"
      ],
      "metadata": {
        "id": "qDCpynPM52zW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Decision Tree classifer object\n",
        "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train,y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "SM6JE1YX6-z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import cross validation score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "## Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(random_state =32)\n",
        "\n",
        "dt_accuracy = cross_val_score(dt,X_train,y_train.values.ravel(), cv=3, scoring ='accuracy')\n",
        "dt_f1 = cross_val_score(dt,X_train,y_train.values.ravel(), cv=3, scoring ='f1')\n",
        "\n",
        "print('dt_accuracy: ' +str(dt_accuracy))\n",
        "print('dt F1_Macro Score: '+str(dt_f1))\n",
        "print('dt_accuracy_avg: ' + str(dt_accuracy.mean()) +'  |  dt_f1_avg: '+str(dt_f1.mean())+'\\n')"
      ],
      "metadata": {
        "id": "OMI9v6yGDSy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "VeqX0Oxr7uiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a parameter grid with distributions of possible parameters to use\n",
        "DT_param_grid = {\n",
        "    'criterion' : ['gini', 'entropy'],\n",
        "    'splitter' : ['best', 'random'],\n",
        "    'max_depth' : [1, 2, 3, 4, 5, 6,7,8,9,10],\n",
        "    'min_samples_split' : [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "}\n",
        "\n",
        "# Create the cross validation object\n",
        "KFold_cv = KFold(n_splits=10, shuffle=True, random_state=2309805)\n",
        "\n",
        "# Instantiate RandomizedSearchCV()\n",
        "DT_model = RandomizedSearchCV(\n",
        "    estimator = DecisionTreeClassifier(random_state = 2309805),\n",
        "    n_iter = 300,\n",
        "    param_distributions = DT_param_grid,\n",
        "    cv = KFold_cv,\n",
        "    verbose = 0,\n",
        "    scoring = 'recall',\n",
        "    n_jobs=-1,\n",
        "    refit=True)\n",
        "\n",
        "# Fit the object to our data\n",
        "DT_model.fit(X_train, y_train)\n",
        "DT_y_pred = DT_model.predict(X_test)\n",
        "\n",
        "# Print the best parameters and highest accuracy\n",
        "print(\"Best parameters found: \", DT_model.best_params_)\n",
        "print(\"\\nBest recall found: \", DT_model.best_score_)"
      ],
      "metadata": {
        "id": "CHdudy2w7uaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "ohekwZe57ztq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelling\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Tree Visualisation\n",
        "from sklearn.tree import export_graphviz\n",
        "from IPython.display import Image\n",
        "import graphviz"
      ],
      "metadata": {
        "id": "PybFBNxs7eAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "metadata": {
        "id": "YufnI8Ux76Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)"
      ],
      "metadata": {
        "id": "MEYjHvpD9fHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the Results\n",
        "\n",
        "# Export the first three decision trees from the forest\n",
        "for i in range(3):\n",
        "    tree = rf.estimators_[i]\n",
        "    dot_data = export_graphviz(tree,\n",
        "                               feature_names=X_train.columns,\n",
        "                               filled=True,\n",
        "                               max_depth=2,\n",
        "                               impurity=False,\n",
        "                               proportion=True)\n",
        "    graph = graphviz.Source(dot_data)\n",
        "    display(graph)"
      ],
      "metadata": {
        "id": "mR88-9lw9mPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a series containing feature importances from the model and feature names from the training data\n",
        "feature_importances = pd.Series(best_rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
        "\n",
        "# Plot a simple bar chart\n",
        "feature_importances.plot.bar();"
      ],
      "metadata": {
        "id": "Q_icFtcF-HOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a parameter grid with distributions of possible parameters to use\n",
        "RF_param_grid = {'bootstrap': [True, False],\n",
        "                 'max_depth': range(2,20,2),\n",
        "                 'max_features': ['log2', 'sqrt'],\n",
        "                 'min_samples_leaf': [1, 2, 4],\n",
        "                 'min_samples_split': [2, 5, 10],\n",
        "                 'criterion' : ['gini', 'entropy'],\n",
        "                 'n_estimators': [50,100, 200, 300]}\n",
        "\n",
        "KFold_cv = KFold(n_splits=10, shuffle=True, random_state=2309805)\n",
        "\n",
        "# Instantiate GridSearchCV() with clf and the parameter grid\n",
        "RF_model = RandomizedSearchCV(\n",
        "    estimator = RandomForestClassifier(random_state = 2309805),\n",
        "    n_iter = 250,\n",
        "    param_distributions = RF_param_grid,\n",
        "    random_state = 2309805,\n",
        "    cv = KFold_cv,\n",
        "    verbose = 0,\n",
        "    scoring = 'recall',\n",
        "    n_jobs=2,\n",
        "    refit=True)\n",
        "\n",
        "# Fit the object to our data\n",
        "RF_model.fit(X_train, y_train)\n",
        "RF_y_pred = RF_model.predict(X_test)\n",
        "\n",
        "# Print the best parameters and highest accuracy\n",
        "print(\"Best parameters found: \", RF_model.best_params_)\n",
        "print(\"Best recall found: \", RF_model.best_score_)"
      ],
      "metadata": {
        "id": "SffN0W7d72ZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "9bHmUg3VDZSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split X and y into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=16)"
      ],
      "metadata": {
        "id": "AbK9nppRGomc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the class\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# instantiate the model (using the default parameters)\n",
        "logreg = LogisticRegression(random_state=16)\n",
        "\n",
        "# fit the model with data\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_test)"
      ],
      "metadata": {
        "id": "JZweeRARGQUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the metrics class\n",
        "from sklearn import metrics\n",
        "\n",
        "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "cnf_matrix"
      ],
      "metadata": {
        "id": "4sL6e0mIGvFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import cross validation score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "## Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression(random_state=32, max_iter = 2000, class_weight = 'balanced')\n",
        "\n",
        "lr_accuracy = cross_val_score(lr,X_train,y_train.values.ravel(), cv=3, scoring ='accuracy')\n",
        "lr_f1 = cross_val_score(lr,X_train,y_train.values.ravel(), cv=3, scoring ='f1')\n",
        "\n",
        "print('lr_accuracy: ' +str(lr_accuracy))\n",
        "print('lr F1_Macro Score: '+str(lr_f1))\n",
        "print('lr_accuracy_avg: ' + str(lr_accuracy.mean()) +'  |  lr_f1_avg: '+str(lr_f1.mean())+'\\n')"
      ],
      "metadata": {
        "id": "Gh7Ua3ocBA4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load libraries\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "ZYsix5Xy7j5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the grid\n",
        "LR_param_grid = {'penalty' : ['l1', 'l2'],\n",
        "    'C' : np.logspace(-4, 4, 20),\n",
        "    'solver' : ['liblinear']}\n",
        "\n",
        "# Create the cross validation object\n",
        "KFold_cv = KFold(n_splits=10, shuffle=True, random_state=2309805)\n",
        "\n",
        "# Instantiate the grid search object\n",
        "LR_model = GridSearchCV(\n",
        "\testimator = LogisticRegression(random_state = 2309805),\n",
        "\tparam_grid = LR_param_grid,\n",
        "\tscoring = 'recall',\n",
        "\tn_jobs=2,\n",
        "\tcv = KFold_cv,\n",
        "\trefit = True,\n",
        "  verbose = 0,\n",
        "\treturn_train_score = True)\n",
        "\n",
        "#Fit the object to our data\n",
        "LR_model.fit(X_train, y_train)\n",
        "# Make predictions\n",
        "LR_y_pred = LR_model.predict(X_test)\n",
        "\n",
        "# Print the best parameters and highest accuracy\n",
        "print(\"Best parameters found: \", LR_model.best_params_)\n",
        "print(\"\\nBest Recall found: \", LR_model.best_score_)"
      ],
      "metadata": {
        "id": "fx2ayVyb7OI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN"
      ],
      "metadata": {
        "id": "JZ992CKkDcAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "Wkb1shJaItsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into features (X) and target (y)\n",
        "X = df.drop('fraud', axis=1)\n",
        "y = df['fraud']\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Scale the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "dSHxkfsxIhgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "S9Vx5jalIfc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)"
      ],
      "metadata": {
        "id": "XAhWuX6iJPNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Cross Validation to Get the Best Value of k\n",
        "k_values = [i for i in range (1,31)]\n",
        "scores = []\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    score = cross_val_score(knn, X, y, cv=5)\n",
        "    scores.append(np.mean(score))\n",
        "\n",
        "\n",
        "# plot\n",
        "sns.lineplot(x = k_values, y = scores, marker = 'o')\n",
        "plt.xlabel(\"K Values\")\n",
        "plt.ylabel(\"Accuracy Score\")"
      ],
      "metadata": {
        "id": "jkGeWF8II3II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import cross validation score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "## KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "\n",
        "knn = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=3))\n",
        "knn_accuracy = cross_val_score(knn,X_train,y_train.values.ravel(), cv=3, scoring ='accuracy')\n",
        "knn_f1 = cross_val_score(knn,X_train,y_train.values.ravel(), cv=3, scoring ='f1')\n",
        "\n",
        "print('knn_accuracy: ' +str(knn_accuracy))\n",
        "print('knn F1_Macro Score: '+str(knn_f1))\n",
        "print('knn_accuracy_avg: ' + str(knn_accuracy.mean()) +'  |  knn_f1_avg: '+str(knn_f1.mean()))"
      ],
      "metadata": {
        "id": "Fs9KN9NZDceH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "OsF5DzLS7oyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a parameter grid with distributions of possible parameters to use\n",
        "KNN_param_grid = {\n",
        "    \"n_neighbors\": np.linspace(1, 30, 30).astype(int),\n",
        "    \"algorithm\" : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "    \"leaf_size\": np.linspace(1, 50, 6).astype(int),\n",
        "    \"p\": [1,2]\n",
        "}\n",
        "\n",
        "# Create the cross validation object\n",
        "KFold_cv = KFold(n_splits=10, shuffle=True, random_state=2309805)\n",
        "\n",
        "# Instantiate GridSearch() with clf and the parameter grid\n",
        "KNN_model = RandomizedSearchCV(\n",
        "    estimator = KNeighborsClassifier(),\n",
        "    n_iter = 200,\n",
        "    param_distributions =  KNN_param_grid,\n",
        "    random_state = 2309805,\n",
        "    cv = KFold_cv,\n",
        "    verbose = 0,\n",
        "    scoring = 'recall',\n",
        "    n_jobs=2,\n",
        "    refit=True)\n",
        "\n",
        "# Fit the object to our data\n",
        "KNN_model.fit(X_train, y_train)\n",
        "KNN_y_pred = KNN_model.predict(X_test)\n",
        "\n",
        "# Print the best parameters and highest accuracy\n",
        "print(\"Best parameters found: \", KNN_model.best_params_)\n",
        "print(\"Best recall found: \", KNN_model.best_score_)"
      ],
      "metadata": {
        "id": "ckFZPM4w7pMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naïve Bayes"
      ],
      "metadata": {
        "id": "1pkQRTusFBfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.33, random_state=125\n",
        ")"
      ],
      "metadata": {
        "id": "BFXSQ1BuSW3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Build a Gaussian Classifier\n",
        "model = GaussianNB()\n",
        "\n",
        "# Model training\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict Output\n",
        "predicted = model.predict([X_test[6]])\n",
        "\n",
        "print(\"Actual Value:\", y_test[6])\n",
        "print(\"Predicted Value:\", predicted[0])"
      ],
      "metadata": {
        "id": "et5VzT1ISVSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import Naive Bayes Classifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#create classifier object\n",
        "nb = GaussianNB()\n",
        "\n",
        "nb_accuracy = cross_val_score(nb,X_train,y_train.values.ravel(), cv=3, scoring ='accuracy')\n",
        "nb_f1 = cross_val_score(nb,X_train,y_train.values.ravel(), cv=3, scoring ='f1')\n",
        "\n",
        "print('nb_accuracy: ' +str(nb_accuracy))\n",
        "print('nb F1_Macro Score: '+str(nb_f1))\n",
        "print('nb_accuracy_avg: ' + str(nb_accuracy.mean()) +'  |  lr_f1_avg: '+str(nb_f1.mean()))"
      ],
      "metadata": {
        "id": "9v5QxyJPFFTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM"
      ],
      "metadata": {
        "id": "nvoPYwga7buN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=109) # 70% training and 30% test\n"
      ],
      "metadata": {
        "id": "Rc0-CSSFTsvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import svm model\n",
        "from sklearn import svm"
      ],
      "metadata": {
        "id": "yAz6ziQg7fx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "Mc6HwDbqTkyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a parameter grid with distributions of possible parameters to use\n",
        "SVM_param_grid = {\n",
        "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
        "    \"C\": [0.1, 1, 10],\n",
        "    \"gamma\": [0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
        "}\n",
        "\n",
        "# Create the cross validation object\n",
        "KFold_cv = KFold(n_splits=10, shuffle=True, random_state=2309805)\n",
        "\n",
        "# Instantiate RandomizedSearchCV() with clf and the parameter grid\n",
        "SVM_model = RandomizedSearchCV(\n",
        "    estimator = svm.SVC(random_state = 2309805),\n",
        "    n_iter = 40,\n",
        "    param_distributions = SVM_param_grid,\n",
        "    cv = KFold_cv,\n",
        "    verbose = 0,\n",
        "    random_state = 2309805,\n",
        "    scoring = 'recall',\n",
        "    n_jobs=2,\n",
        "    refit=True)\n",
        "\n",
        "# Fit the object to our data\n",
        "SVM_model.fit(X_train, y_train)\n",
        "SVM_y_pred = SVM_model.predict(X_test)\n",
        "\n",
        "# Print the best parameters and highest accuracy\n",
        "print(\"Best parameters found: \", SVM_model.best_params_)\n",
        "print(\"\\nBest recall found: \", SVM_model.best_score_)"
      ],
      "metadata": {
        "id": "bYDyBmwx7c2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models Regression"
      ],
      "metadata": {
        "id": "2EGPsC4cF2kY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression"
      ],
      "metadata": {
        "id": "DUsogb8gGXWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})"
      ],
      "metadata": {
        "id": "ek7lWzKjGi94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to flatten 2D lists so it can be used by plotly\n",
        "def flatten(l):\n",
        "    return [item for sublist in l for item in sublist]\n",
        "\n",
        "# Set up and fit the linear regressor\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "\n",
        "# Flatten the prediction and expected lists\n",
        "predicted = flatten(lin_reg.predict(X_test))\n",
        "expected = flatten(y_test.values)"
      ],
      "metadata": {
        "id": "Fuszv_59GhgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "# Import plotting package\n",
        "import plotly.express as px\n",
        "\n",
        "# Put data to plot in dataframe\n",
        "df_plot = pd.DataFrame({'expected':expected, 'predicted':predicted})\n",
        "\n",
        "# Make scatter plot from data\n",
        "fig = px.scatter(\n",
        "    df_plot,\n",
        "    x='expected',\n",
        "    y='predicted',\n",
        "    title='Predicted vs. Actual Values')\n",
        "\n",
        "# Add straight line indicating perfect model\n",
        "fig.add_shape(type=\"line\",\n",
        "    x0=0, y0=0, x1=50, y1=50,\n",
        "    line=dict(\n",
        "        color=\"Red\",\n",
        "        width=4,\n",
        "        dash=\"dot\",\n",
        "    )\n",
        ")\n",
        "\n",
        "# Show figure\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "5D1k38s-GlC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the root mean square error (RMS)\n",
        "error = np.sqrt(np.mean((np.array(predicted) - np.array(expected)) ** 2))\n",
        "print(f\"RMS: {error:.4f} \")\n",
        "\n",
        "r2=r2_score(expected, predicted)\n",
        "print(f\"R2: {round(r2,4)}\")"
      ],
      "metadata": {
        "id": "zhHqRZaVGr6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameter Tuning"
      ],
      "metadata": {
        "id": "Ie211A6NGMuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manual Parameter Tuning"
      ],
      "metadata": {
        "id": "m1iprtcIGO26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Knn Model Comparison\n",
        "\n",
        "#here we will loop through and see which value of k performs the best.\n",
        "\n",
        "for i in range(1,7):\n",
        "    knn = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=i))\n",
        "    knn_f1 = cross_val_score(knn,X_train,y_train.values.ravel(), cv=3, scoring ='f1')\n",
        "    print('K ='+(str(i)) + (': ') + str(knn_f1.mean()))"
      ],
      "metadata": {
        "id": "q6v8Sq9nGbVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Randomized Parameter Tuning"
      ],
      "metadata": {
        "id": "njE9LY_VGR-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state = 42)\n",
        "\n",
        "features = {'criterion': ['gini','entropy'],\n",
        "            'splitter': ['best','random'],\n",
        "           'max_depth': [2,5,10,20,40,None],\n",
        "           'min_samples_split': [2,5,10,15],\n",
        "           'max_features': ['auto','sqrt','log2',None]}\n",
        "\n",
        "rs_dt = RandomizedSearchCV(estimator = dt,\n",
        "                           param_distributions = features,\n",
        "                           n_iter = 100,\n",
        "                           cv = 3,\n",
        "                           random_state = 42,\n",
        "                           scoring = 'f1')\n",
        "\n",
        "rs_dt.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "o6_lLL5wG1BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('best stcore = ' + str(rs_dt.best_score_))\n",
        "print('best params = ' + str(rs_dt.best_params_))"
      ],
      "metadata": {
        "id": "17DC5nDSG_tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GridsearchCV (Exhaustive Parameter Tuning)"
      ],
      "metadata": {
        "id": "UsVu1dmyGUaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "features_gs = {'criterion': ['entropy'],\n",
        "            'splitter': ['random'],\n",
        "           'max_depth': np.arange(30,50,1), #getting more precise within range\n",
        "           'min_samples_split': [2,3,4,5,6,7,8,9],\n",
        "           'max_features': [None]}\n",
        "\n",
        "gs_dt = GridSearchCV(estimator = dt,\n",
        "                     param_grid = features_gs,\n",
        "                     cv = 3,\n",
        "                     scoring ='f1') #we don't need random state because there isn't randomization like before\n",
        "\n",
        "gs_dt.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "SnFE3rzvHFiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('best stcore = ' + str(gs_dt.best_score_))\n",
        "print('best params = ' + str(gs_dt.best_params_))"
      ],
      "metadata": {
        "id": "SaebcDzrHGwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bayesian Optimization"
      ],
      "metadata": {
        "id": "pxhC-ijoHTEZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an iterative process where our model improves its understandings of the feature inputs as it goes."
      ],
      "metadata": {
        "id": "0ErMqvkMHkjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "metadata": {
        "id": "4Ngfgd2vHVq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "\n",
        "# Choose cross validation method\n",
        "cv = StratifiedKFold(n_splits = 3)\n",
        "\n",
        "\n",
        "bs_lr = BayesSearchCV(\n",
        "    dt,\n",
        "    {'criterion': Categorical(['gini','entropy']),\n",
        "            'splitter': Categorical(['best','random']),\n",
        "           'max_depth': Integer(10,50),\n",
        "           'min_samples_split': Integer(2,15),\n",
        "           'max_features': Categorical(['auto','sqrt','log2',None])},\n",
        "    random_state=42,\n",
        "    n_iter= 100,\n",
        "    cv= cv,\n",
        "    scoring ='f1')\n",
        "\n",
        "bs_lr.fit(X_train,y_train.values.ravel())"
      ],
      "metadata": {
        "id": "s_Iv9JrFHWHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('best stcore = ' + str(bs_lr.best_score_))\n",
        "print('best params = ' + str(bs_lr.best_params_))"
      ],
      "metadata": {
        "id": "fd7Sm5GfHapx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selecting a model  \n",
        "\n",
        "We also want to use other considerations like training time, prediction time or interperetability to select selct the best model for our use case.\n"
      ],
      "metadata": {
        "id": "0siYIwR3Hv-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble model  \n",
        "\n",
        "Since we have one tuned model, lets see if we can improve it by combining it with a few of the other models we have used. This process is called ensembling. In the case of classification, we often use a popular vote metric to select the best model."
      ],
      "metadata": {
        "id": "uqOZZJ5zIGdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "dt_voting = DecisionTreeClassifier(**{'criterion': 'entropy',\n",
        "                                      'max_depth': 44,\n",
        "                                      'max_features': None,\n",
        "                                      'min_samples_split': 2,\n",
        "                                      'splitter': 'random'}) # ** allows you to pass in parameters as dict\n",
        "knn_voting = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=1))\n",
        "lr_voting = LogisticRegression(random_state=32, max_iter = 2000, class_weight = 'balanced')\n",
        "\n",
        "ens = VotingClassifier(estimators = [('dt', dt_voting),('knn', knn_voting), ('lr',lr_voting)], voting = 'hard')"
      ],
      "metadata": {
        "id": "8996OaYKICZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voting_accuracy = cross_val_score(ens,X_train,y_train.values.ravel(), cv=3, scoring ='accuracy')\n",
        "voting_f1 = cross_val_score(ens,X_train,y_train.values.ravel(), cv=3, scoring ='f1')\n",
        "\n",
        "print('voting_accuracy: ' +str(voting_accuracy))\n",
        "print('voting F1_Macro Score: '+str(voting_f1))\n",
        "print('voting_accuracy_avg: ' + str(voting_accuracy.mean()) +'  |  voting_f1_avg: '+str(voting_f1.mean()))"
      ],
      "metadata": {
        "id": "XZ7rrhc1IlgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ens = VotingClassifier(estimators = [('dt', dt_voting), ('knn', knn_voting), ('lr',lr_voting)], voting = 'soft')\n",
        "voting_accuracy = cross_val_score(ens,X_train,y_train.values.ravel(), cv=3, scoring ='accuracy')\n",
        "voting_f1 = cross_val_score(ens,X_train,y_train.values.ravel(), cv=3, scoring ='f1')\n",
        "\n",
        "print('voting_accuracy: ' +str(voting_accuracy))\n",
        "print('voting F1_Macro Score: '+str(voting_f1))\n",
        "print('voting_accuracy_avg: ' + str(voting_accuracy.mean()) +'  |  voting_f1_avg: '+str(voting_f1.mean()))"
      ],
      "metadata": {
        "id": "GswIVRTrIldj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}